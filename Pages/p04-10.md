# 🔰 **STAGE 10 — Complete Real-World Case Study**

---

## 🎯 **Scenario: Sales Forecasting**

We have **daily sales data** for 2 years. Our task:

* Analyze data
* Check stationarity
* Model it
* Forecast next 60 days
* Evaluate model performance

---

### ✅ **Step 1 — Load & Explore Data**

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Simulate 2 years daily sales data
date_rng = pd.date_range(start='2022-01-01', end='2023-12-31', freq='D')
sales = 300 + 20*np.sin(2*np.pi*date_rng.dayofyear/365) + np.random.normal(0, 10, size=len(date_rng))

df = pd.DataFrame({'Date': date_rng, 'Sales': sales})
df.set_index('Date', inplace=True)

plt.figure(figsize=(12,6))
plt.plot(df['Sales'])
plt.title("Daily Sales Data (Simulated)")
plt.show()
```

👉 You’ll see a seasonal pattern + noise.

---

### ✅ **Step 2 — Decompose the Series**

```python
from statsmodels.tsa.seasonal import seasonal_decompose

result = seasonal_decompose(df['Sales'], model='additive', period=365)
result.plot()
plt.show()
```

👉 We see clear **trend + seasonality**.

---

### ✅ **Step 3 — Check Stationarity**

```python
from statsmodels.tsa.stattools import adfuller

adf_result = adfuller(df['Sales'])
print(f'ADF Statistic: {adf_result[0]}')
print(f'p-value: {adf_result[1]}')
```

👉 Likely non-stationary (seasonality & trend).

---

### ✅ **Step 4 — Apply Log + Differencing**

```python
df['Sales_log'] = np.log(df['Sales'])
df['Sales_log_diff'] = df['Sales_log'].diff().dropna()

plt.figure(figsize=(12,6))
plt.plot(df['Sales_log_diff'])
plt.title("After Log & Differencing")
plt.show()

# ADF Test again
adf_result_diff = adfuller(df['Sales_log_diff'].dropna())
print(f'p-value after differencing: {adf_result_diff[1]}')
```

👉 Likely stationary now.

---

### ✅ **Step 5 — Auto ARIMA Modeling**

```python
import pmdarima as pm

model_auto = pm.auto_arima(df['Sales'], 
                            seasonal=True, 
                            m=365, 
                            stepwise=True,
                            suppress_warnings=True,
                            trace=True)

print(model_auto.summary())
```

👉 It will select best ARIMA+seasonal parameters.

---

### ✅ **Step 6 — Forecast Next 60 Days**

```python
n_periods = 60
future_forecast, conf_int = model_auto.predict(n_periods=n_periods, return_conf_int=True)

# Create forecast index
forecast_dates = pd.date_range(df.index[-1] + pd.Timedelta(days=1), periods=n_periods)

plt.figure(figsize=(12,6))
plt.plot(df['Sales'], label='Historical')
plt.plot(forecast_dates, future_forecast, label='Forecast', color='red')
plt.fill_between(forecast_dates, conf_int[:,0], conf_int[:,1], color='pink', alpha=0.3)
plt.title("Sales Forecast - 60 Days Ahead")
plt.legend()
plt.grid(True)
plt.show()
```

---

### ✅ **Step 7 — Model Evaluation**

Let’s simulate train-test split:

```python
train = df['Sales'].iloc[:-60]
test = df['Sales'].iloc[-60:]

# Fit model on train
model_train = pm.auto_arima(train, seasonal=True, m=365, stepwise=True, suppress_warnings=True)

forecast_test = model_train.predict(n_periods=60)

# Evaluate
from sklearn.metrics import mean_squared_error, mean_absolute_error

rmse = np.sqrt(mean_squared_error(test, forecast_test))
mae = mean_absolute_error(test, forecast_test)

print(f"Test RMSE: {rmse:.2f}")
print(f"Test MAE: {mae:.2f}")
```

---

### ✅ **Optional — Try Prophet**

```python
from prophet import Prophet

df_prophet = df.reset_index().rename(columns={'Date': 'ds', 'Sales': 'y'})
model_prophet = Prophet(yearly_seasonality=True)
model_prophet.fit(df_prophet)

future = model_prophet.make_future_dataframe(periods=60)
forecast = model_prophet.predict(future)

model_prophet.plot(forecast)
plt.title("Prophet Forecast - 60 Days")
plt.show()

model_prophet.plot_components(forecast)
plt.show()
```

👉 Very easy, handles trend + seasonality automatically.

---

---

# 🔰 **Key Takeaways from This Full Case Study:**

✅ We:

* Handled non-stationarity (log, differencing)
* Modeled with ARIMA and Prophet
* Forecasted future
* Validated forecast accuracy

---

👉 This is **exactly** how you do full-scale **professional time series forecasting**.

---

# 🔰 **CONGRATULATIONS!**

✅ You have now completed the full **Progressive Time Series Learning Track**.

---

# 🎁 **Optional Bonus Topics (if you want):**

* ✅ Multivariate models (VAR)
* ✅ Deep learning (LSTM, GRU)
* ✅ Anomaly detection in production
* ✅ Deployment techniques

---
