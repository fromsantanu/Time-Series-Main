# Forecast Accuracy Testing

## 🌟 **1. What is Forecast Accuracy Testing? (Layman Explanation)**

✅ **Imagine you predicted tomorrow’s temperature.**

* Predicted: **30°C**
* Actual: **32°C**

The **difference (error) is 2°C**.

🔑 **Forecast accuracy tests measure how close your model’s predictions are to actual values.**

---

### 🧠 **Why Important?**

✔️ Helps you know **which model predicts better**.
✔️ Ensures you choose a model with **minimum error for reliable forecasting**.

---

## 🔬 **2. Technical Definition**

### **Common Forecast Accuracy Metrics:**

1. **MAE (Mean Absolute Error)**

   * Average of absolute errors.
   * **Easy to interpret** in same units as data.

2. **MSE (Mean Squared Error)**

   * Average of squared errors.
   * Penalizes **large errors more**.

3. **RMSE (Root Mean Squared Error)**

   * Square root of MSE.
   * Same units as data, penalizes large errors.

4. **MAPE (Mean Absolute Percentage Error)**

   * Average of absolute percentage errors.
   * **Expressed as % → scale-free**.

5. **Theil’s U Statistic**

   * Compares model forecast vs naive forecast.

---

### ✅ **When to Use Which?**

| Metric       | Good for                                                 |
| ------------ | -------------------------------------------------------- |
| **MAE**      | Simple average error magnitude                           |
| **MSE/RMSE** | When large errors are undesirable                        |
| **MAPE**     | Comparing performance across datasets (percentage error) |

---

## 🐍 **3. How to Perform Forecast Accuracy Tests in Python**

Here is a **step-by-step practical example**:

---

### 🔷 **Step 1. Import libraries and create sample data**

```python
import pandas as pd
import numpy as np
from sklearn.metrics import mean_absolute_error, mean_squared_error

# Simulated actual and forecast data
actual = np.array([100, 110, 120, 130, 140])
forecast = np.array([102, 108, 123, 128, 142])
```

---

### 🔷 **Step 2. Calculate MAE**

```python
mae = mean_absolute_error(actual, forecast)
print("Mean Absolute Error (MAE):", mae)
```

---

### 🔷 **Step 3. Calculate MSE and RMSE**

```python
mse = mean_squared_error(actual, forecast)
rmse = np.sqrt(mse)

print("Mean Squared Error (MSE):", mse)
print("Root Mean Squared Error (RMSE):", rmse)
```

---

### 🔷 **Step 4. Calculate MAPE**

```python
mape = np.mean(np.abs((actual - forecast) / actual)) * 100
print("Mean Absolute Percentage Error (MAPE):", mape, "%")
```

---

### 🔷 **Step 5. Interpretation**

✅ **Lower values indicate better forecasts.**

* **MAE:** Average error magnitude
* **RMSE:** Similar to MAE, but penalizes larger errors more
* **MAPE:** Model is off by X% on average

---

### 🔷 **Step 6. Example Output Explanation**

```
MAE = 2.2
RMSE = 2.28
MAPE = 1.82%
```

✔️ **Forecast is accurate within \~2 units or \~1.8% on average.**

---

## 💡 **4. Final Summary (Layman)**

✔️ **Forecast accuracy tests check how close predictions are to real data.**
✔️ **Why important?** To choose **best performing model** for future predictions.
✔️ **How to check?** Calculate **MAE, RMSE, MAPE** using **scikit-learn** or manually in Python.

---
